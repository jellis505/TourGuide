The training dataset for TourDruid comprises approximately 1100 images of 17 buildings across Columbia University campus. The photographs were captured by the team using 5-megapixel cameras from our smart phones and then downscaled to 0.3 Megapixels and converted into grayscale. We chose to use our smart phone cameras to take the images for our training set since it is the same camera the application will use. Since we cannot predict where a user will be standing when they take a picture, the dataset images were captured at many different angles and distances from each landmark so the dataset could be more robust. After processing the images, our dataset reaches 173MB in size, and generates approximately 494K features.

Every time a user takes a picture with our application and clicks on a result, our server saves that image, tags it with a building name, and adds it to the database. The application will perform frequent builds that reconstruct the classifier with the new images. Though this functionality makes our classifier more robust over time, it is possible for a user to confirm the wrong building, which may lead to more false positives. In order to prevent users from confirming the wrong building on the application, an image of the building is displayed next to each result so that the user can verify our results. This means that our dataset consistency is partly dependent on the honesty of the user, yet we predict that users will correctly confirm results a majority of the time.